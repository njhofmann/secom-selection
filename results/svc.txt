training results for model: svc, selector function: f_classif, percentile: 1
info: 0
selected features: [ 26  54  96 293 351]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7649659863945578, precision=0.21875, recall=0.7, f1=0.3333333333333333, roc_auc=0.7649659863945578)

info: 1
selected features: [ 54  96 409 438 441]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6251700680272109, precision=0.15384615384615385, recall=0.4, f1=0.2222222222222222, roc_auc=0.6251700680272109)

info: 2
selected features: [ 54  96 351 354 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6173469387755102, precision=0.11363636363636363, recall=0.5, f1=0.18518518518518517, roc_auc=0.6173469387755102)

info: 3
selected features: [ 54  96 293 351 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.673412204234122, precision=0.17142857142857143, recall=0.5454545454545454, f1=0.26086956521739124, roc_auc=0.673412204234122)

info: 4
selected features: [ 26  54  96 293 409]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7814445828144458, precision=0.25, recall=0.7272727272727273, f1=0.37209302325581395, roc_auc=0.7814445828144458)

info: 5
selected features: [ 54  96 293 351 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6348069738480697, precision=0.15625, recall=0.45454545454545453, f1=0.2325581395348837, roc_auc=0.6348069738480697)

info: 6
selected features: [ 54  96 192 293 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6983188044831881, precision=0.16666666666666666, recall=0.6363636363636364, f1=0.2641509433962264, roc_auc=0.698318804483188)

info: 7
selected features: [ 54  96 293 351 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6938356164383561, precision=0.16216216216216217, recall=0.6, f1=0.25531914893617025, roc_auc=0.6938356164383562)

info: 8
selected features: [ 54  96 293 351 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7075342465753425, precision=0.18181818181818182, recall=0.6, f1=0.27906976744186046, roc_auc=0.7075342465753426)

info: 9
selected features: [ 54  96 293 351 354]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6383561643835616, precision=0.18181818181818182, recall=0.4, f1=0.25000000000000006, roc_auc=0.6383561643835616)

score averages:
average balanced accuracy: 0.6835191585974365
average precision: 0.17563762813762815
average recall: 0.5563636363636364
average f1 score: 0.26548013285230865
average roc auc score: 0.6835191585974365
feature counts: Counter({54: 10, 96: 10, 293: 8, 409: 8, 351: 7, 26: 2, 354: 2, 438: 1, 441: 1, 192: 1})
feature stability score: 0.8888888888888888


training results for model: svc, selector function: mutual_info_classif, percentile: 1
info: 0
selected features: [ 39 117 387 414 425]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.592517006802721, precision=0.08955223880597014, recall=0.6, f1=0.1558441558441558, roc_auc=0.592517006802721)

info: 1
selected features: [120 276 387 457 459]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5598639455782313, precision=0.07407407407407407, recall=0.8, f1=0.13559322033898305, roc_auc=0.5598639455782313)

info: 2
selected features: [233 264 337 457 461]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6074829931972789, precision=0.0851063829787234, recall=0.8, f1=0.15384615384615383, roc_auc=0.6074829931972789)

info: 3
selected features: [ 39 387 455 459 461]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6348069738480697, precision=0.15625, recall=0.45454545454545453, f1=0.2325581395348837, roc_auc=0.6348069738480697)

info: 4
selected features: [337 363 387 459 461]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5208592777085927, precision=0.0784313725490196, recall=0.36363636363636365, f1=0.12903225806451613, roc_auc=0.5208592777085929)

info: 5
selected features: [ 39 233 454 455 457]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.44209215442092153, precision=0.05405405405405406, recall=0.36363636363636365, f1=0.09411764705882354, roc_auc=0.44209215442092165)

info: 6
selected features: [ 39  51 117 276 363]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5647571606475716, precision=0.08641975308641975, recall=0.6363636363636364, f1=0.15217391304347824, roc_auc=0.5647571606475715)

info: 7
selected features: [ 39 243 363 387 425]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.43904109589041096, precision=0.04081632653061224, recall=0.2, f1=0.06779661016949151, roc_auc=0.43904109589041096)

info: 8
selected features: [425 454 455 457 461]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.4904109589041096, precision=0.058823529411764705, recall=0.2, f1=0.0909090909090909, roc_auc=0.4904109589041096)

info: 9
selected features: [243 363 387 425 459]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6732876712328767, precision=0.13953488372093023, recall=0.6, f1=0.22641509433962265, roc_auc=0.6732876712328767)

score averages:
average balanced accuracy: 0.5525119238230785
average precision: 0.08630626152115682
average recall: 0.5018181818181818
average f1 score: 0.14382862831491994
average roc auc score: 0.5525119238230785
feature counts: Counter({387: 6, 39: 5, 425: 4, 457: 4, 459: 4, 461: 4, 363: 4, 455: 3, 117: 2, 276: 2, 233: 2, 337: 2, 454: 2, 243: 2, 414: 1, 120: 1, 264: 1, 51: 1})
feature stability score: 0.7111111111111111


training results for model: svc, selector function: f_classif, percentile: 5
info: 0
selected features: [ 19  26  31  54  59  73  96 114 115 116 117 118 122 151 154 192 215 250
 268 293 351 354 385 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7149659863945579, precision=0.1935483870967742, recall=0.6, f1=0.2926829268292683, roc_auc=0.7149659863945579)

info: 1
selected features: [ 19  26  54  59  96 122 150 151 154 155 156 192 249 250 253 254 255 293
 350 351 354 355 356 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6717687074829932, precision=0.17857142857142858, recall=0.5, f1=0.2631578947368421, roc_auc=0.6717687074829932)

info: 2
selected features: [ 19  26  54  96 107 122 154 155 156 192 253 254 255 268 293 350 351 354
 355 356 409 435 438 441]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5605442176870749, precision=0.08888888888888889, recall=0.4, f1=0.14545454545454545, roc_auc=0.5605442176870749)

info: 3
selected features: [ 19  24  26  54  96 114 117 122 150 154 155 156 192 249 253 254 255 293
 350 351 354 355 356 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6528642590286426, precision=0.14634146341463414, recall=0.5454545454545454, f1=0.23076923076923073, roc_auc=0.6528642590286426)

info: 4
selected features: [ 12  19  26  54  73  96 115 118 120 122 123 151 169 192 250 268 293 350
 351 354 355 356 369 409]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5594645080946451, precision=0.09259259259259259, recall=0.45454545454545453, f1=0.15384615384615383, roc_auc=0.5594645080946451)

info: 5
selected features: [ 19  26  31  54  96 114 117 118 122 143 154 169 242 250 253 268 293 350
 351 354 355 356 357 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7584059775840598, precision=0.16981132075471697, recall=0.8181818181818182, f1=0.28125, roc_auc=0.7584059775840599)

info: 6
selected features: [ 19  26  31  54  96 114 116 117 122 151 154 192 215 250 253 268 293 350
 351 354 355 356 357 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6108343711083437, precision=0.1282051282051282, recall=0.45454545454545453, f1=0.19999999999999996, roc_auc=0.6108343711083437)

info: 7
selected features: [ 19  26  54  96 107 117 122 151 154 155 217 249 250 253 254 268 293 320
 350 351 354 355 356 409]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6732876712328767, precision=0.13953488372093023, recall=0.6, f1=0.22641509433962265, roc_auc=0.6732876712328767)

info: 8
selected features: [ 19  26  54  96 117 122 151 154 155 156 192 249 250 253 254 255 293 350
 351 354 355 356 387 409]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7404109589041096, precision=0.1794871794871795, recall=0.7, f1=0.2857142857142857, roc_auc=0.7404109589041096)

info: 9
selected features: [ 19  20  24  26  54  96 118 122 150 154 155 156 192 249 253 254 255 293
 350 351 354 355 356 409]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.8006849315068494, precision=0.21621621621621623, recall=0.8, f1=0.3404255319148936, roc_auc=0.8006849315068493)

score averages:
average balanced accuracy: 0.6743231589024152
average precision: 0.15331974889484895
average recall: 0.5872727272727273
average f1 score: 0.24197156636048422
average roc auc score: 0.6743231589024152
feature counts: Counter({19: 10, 26: 10, 54: 10, 96: 10, 122: 10, 293: 10, 351: 10, 354: 10, 409: 10, 154: 9, 350: 9, 355: 9, 356: 9, 192: 8, 253: 8, 250: 7, 117: 6, 151: 6, 268: 6, 155: 6, 254: 6, 156: 5, 249: 5, 255: 5, 114: 4, 118: 4, 31: 3, 150: 3, 59: 2, 73: 2, 115: 2, 116: 2, 215: 2, 107: 2, 24: 2, 169: 2, 357: 2, 385: 1, 435: 1, 438: 1, 441: 1, 12: 1, 120: 1, 123: 1, 369: 1, 143: 1, 242: 1, 217: 1, 320: 1, 387: 1, 20: 1})
feature stability score: 0.875


/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
training results for model: svc, selector function: mutual_info_classif, percentile: 5
info: 0
selected features: [  5  39  51  60 115 123 163 230 231 232 233 276 328 329 337 348 363 409
 425 454 455 457 459 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6217687074829932, precision=0.14814814814814814, recall=0.4, f1=0.21621621621621623, roc_auc=0.6217687074829932)

info: 1
selected features: [ 31  35  36  38  39  60 115 117 121 215 230 233 327 328 337 348 363 387
 425 454 455 457 459 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 2
selected features: [ 31  35  38  39  60 114 120 121 127 168 215 262 264 267 276 363 366 368
 387 414 423 425 454 455]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 3
selected features: [ 31  33  38  39  51  60 121 123 233 245 276 310 328 329 333 336 387 424
 425 454 455 457 458 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 4
selected features: [ 39  60 118 120 121 123 125 232 276 327 328 333 348 363 387 409 414 425
 445 454 455 457 458 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5273972602739726, precision=0.0738255033557047, recall=1.0, f1=0.1375, roc_auc=0.5273972602739726)

info: 5
selected features: [ 31  38  39 117 120 123 127 144 243 276 328 329 337 348 363 387 425 454
 455 457 458 459 461 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 6
selected features: [ 31  37  38  39  60  64  85 117 119 120 121 125 127 225 230 233 265 327
 328 337 363 367 425 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 7
selected features: [  5  31  35  37  39  60  82 121 125 126 130 230 306 329 377 387 409 424
 425 454 455 457 461 467]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.4835616438356164, precision=0.05555555555555555, recall=0.2, f1=0.08695652173913045, roc_auc=0.4835616438356164)

info: 8
selected features: [ 31  38  39  60  78 117 118 120 131 231 233 276 328 329 333 337 363 387
 425 454 455 457 459 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.4527397260273973, precision=0.044444444444444446, recall=0.2, f1=0.07272727272727272, roc_auc=0.4527397260273972)

info: 9
selected features: [ 23  31  33  38  39  60  85 121 124 127 233 243 265 276 348 363 387 409
 414 454 455 459 461 467]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6383561643835616, precision=0.18181818181818182, recall=0.4, f1=0.25000000000000006, roc_auc=0.6383561643835616)

score averages:
average balanced accuracy: 0.5223823502003541
average precision: 0.07139829161245824
average recall: 0.52
average f1 score: 0.11562571535397623
average roc auc score: 0.5223823502003541
feature counts: Counter({39: 10, 60: 9, 425: 9, 454: 9, 455: 9, 363: 8, 461: 8, 31: 8, 387: 8, 276: 7, 328: 7, 457: 7, 38: 7, 121: 7, 233: 6, 329: 5, 337: 5, 348: 5, 459: 5, 120: 5, 123: 4, 230: 4, 409: 4, 117: 4, 127: 4, 35: 3, 327: 3, 414: 3, 333: 3, 458: 3, 125: 3, 5: 2, 51: 2, 115: 2, 231: 2, 232: 2, 215: 2, 473: 2, 33: 2, 424: 2, 118: 2, 243: 2, 37: 2, 85: 2, 265: 2, 467: 2, 163: 1, 36: 1, 114: 1, 168: 1, 262: 1, 264: 1, 267: 1, 366: 1, 368: 1, 423: 1, 245: 1, 310: 1, 336: 1, 445: 1, 144: 1, 64: 1, 119: 1, 225: 1, 367: 1, 82: 1, 126: 1, 130: 1, 306: 1, 377: 1, 78: 1, 131: 1, 23: 1, 124: 1})
feature stability score: 0.7685185185185185


training results for model: svc, selector function: f_classif, percentile: 10
info: 0
selected features: [ 12  19  20  24  26  38  54  59  73  89  93  96 107 114 115 117 118 120
 122 123 150 151 154 155 156 169 192 195 217 249 250 253 254 255 268 293
 296 320 350 351 354 355 356 357 369 376 409 410]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5979591836734695, precision=0.11764705882352941, recall=0.4, f1=0.1818181818181818, roc_auc=0.5979591836734693)

info: 1
selected features: [ 19  26  30  31  51  54  59  73  89  93  96 114 115 116 117 118 120 122
 123 126 151 154 155 157 169 182 192 215 249 250 253 254 255 268 282 293
 350 351 354 355 356 357 369 376 378 381 409 414]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6639455782312925, precision=0.13043478260869565, recall=0.6, f1=0.21428571428571427, roc_auc=0.6639455782312924)

info: 2
selected features: [ 19  20  26  31  54  73  93  96 104 107 114 115 116 117 118 120 122 123
 126 151 154 155 156 169 179 181 182 192 217 250 253 254 255 268 278 282
 293 309 320 350 351 354 355 356 369 379 381 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6445578231292517, precision=0.1388888888888889, recall=0.5, f1=0.2173913043478261, roc_auc=0.6445578231292517)

info: 3
selected features: [ 12  19  20  24  26  31  38  54  59  93  96 107 114 115 116 117 118 120
 122 123 143 150 151 154 155 156 169 192 215 217 242 249 250 253 254 255
 268 293 320 345 350 351 354 355 356 369 409 414]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6528642590286426, precision=0.14634146341463414, recall=0.5454545454545454, f1=0.23076923076923073, roc_auc=0.6528642590286426)

info: 4
selected features: [ 12  19  24  26  31  51  54  64  73  96 107 114 116 117 118 122 123 151
 154 155 169 172 182 192 217 250 253 268 271 293 320 350 351 354 355 356
 357 369 372 378 381 409 434 435 437 438 440 441]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5868617683686177, precision=0.10869565217391304, recall=0.45454545454545453, f1=0.1754385964912281, roc_auc=0.5868617683686177)

info: 5
selected features: [ 12  19  20  24  26  31  36  54  58  59  60  73  96 107 114 115 117 118
 122 123 126 150 151 154 155 156 169 192 217 249 250 253 254 255 268 293
 320 350 351 354 355 356 357 369 409 435 438 441]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6279576587795765, precision=0.14705882352941177, recall=0.45454545454545453, f1=0.22222222222222224, roc_auc=0.6279576587795765)

info: 6
selected features: [ 12  19  20  24  26  31  54  58  59  73  96 114 115 117 118 119 120 122
 123 150 151 154 155 156 169 178 179 181 187 192 215 249 250 253 254 255
 268 286 293 350 351 354 355 356 369 379 387 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7129514321295143, precision=0.15384615384615385, recall=0.7272727272727273, f1=0.253968253968254, roc_auc=0.7129514321295143)

info: 7
selected features: [ 12  19  20  24  26  31  54  59  73  93  96 104 107 114 115 116 117 118
 119 120 122 123 150 151 154 155 156 169 192 215 217 249 250 253 254 255
 268 293 320 350 351 354 355 356 369 376 409 414]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6506849315068493, precision=0.14705882352941177, recall=0.5, f1=0.22727272727272727, roc_auc=0.6506849315068494)

info: 8
selected features: [ 19  20  24  26  31  53  54  59  73  96 107 114 115 116 117 118 120 122
 123 126 150 151 154 155 156 169 182 192 215 217 249 250 253 254 255 268
 282 293 320 350 351 354 355 356 357 369 376 409]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6698630136986301, precision=0.13636363636363635, recall=0.6, f1=0.22222222222222218, roc_auc=0.6698630136986302)

info: 9
selected features: [ 19  20  24  26  31  51  53  54  59  73  89  96 107 114 115 116 117 118
 120 122 123 126 150 151 154 155 156 169 192 215 217 249 250 253 254 255
 268 293 320 350 351 354 355 356 357 369 376 409]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5732876712328767, precision=0.0975609756097561, recall=0.4, f1=0.15686274509803924, roc_auc=0.5732876712328766)

score averages:
average balanced accuracy: 0.6380933319778721
average precision: 0.1323896258788031
average recall: 0.5181818181818182
average f1 score: 0.2102251198495646
average roc auc score: 0.6380933319778721
feature counts: Counter({19: 10, 26: 10, 54: 10, 96: 10, 114: 10, 117: 10, 118: 10, 122: 10, 123: 10, 151: 10, 154: 10, 155: 10, 169: 10, 192: 10, 250: 10, 253: 10, 268: 10, 293: 10, 350: 10, 351: 10, 354: 10, 355: 10, 356: 10, 369: 10, 409: 10, 73: 9, 115: 9, 254: 9, 255: 9, 31: 9, 20: 8, 24: 8, 59: 8, 107: 8, 120: 8, 156: 8, 217: 8, 249: 8, 320: 8, 150: 7, 116: 7, 12: 6, 357: 6, 215: 6, 93: 5, 376: 5, 126: 5, 182: 4, 89: 3, 51: 3, 282: 3, 381: 3, 414: 3, 38: 2, 378: 2, 104: 2, 179: 2, 181: 2, 379: 2, 435: 2, 438: 2, 441: 2, 58: 2, 119: 2, 53: 2, 195: 1, 296: 1, 410: 1, 30: 1, 157: 1, 278: 1, 309: 1, 143: 1, 242: 1, 345: 1, 64: 1, 172: 1, 271: 1, 372: 1, 434: 1, 437: 1, 440: 1, 36: 1, 60: 1, 178: 1, 187: 1, 286: 1, 387: 1})
feature stability score: 0.9074074074074074


training results for model: svc, selector function: mutual_info_classif, percentile: 10
info: 0
selected features: [  2   5  33  39  50  51  52  53  60  78 115 117 118 120 121 123 126 134
 165 230 231 232 233 260 262 263 264 265 276 328 333 334 337 363 368 387
 409 423 425 446 454 455 457 458 459 461 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6064625850340136, precision=0.08181818181818182, recall=0.9, f1=0.15, roc_auc=0.6064625850340135)

info: 1
selected features: [  2   5  26  31  38  39  50  51  53  54  59  60  78 118 120 121 123 124
 125 163 177 215 226 230 231 233 234 243 265 267 276 310 327 328 333 334
 337 363 367 387 409 423 425 454 455 457 461 467]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7149659863945579, precision=0.1935483870967742, recall=0.6, f1=0.2926829268292683, roc_auc=0.7149659863945579)

info: 2
selected features: [  2   5  31  35  38  39  54  60  64 119 121 123 125 127 130 131 135 144
 163 166 177 230 231 232 233 243 245 260 264 265 276 306 327 333 334 335
 336 337 348 363 366 367 387 425 455 459 460 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6683673469387755, precision=0.1724137931034483, recall=0.5, f1=0.25641025641025644, roc_auc=0.6683673469387756)

info: 3
selected features: [  3  12  31  38  39  60  64  78  83 115 117 118 119 120 121 123 124 125
 126 127 164 177 211 225 226 230 233 267 327 328 329 333 336 363 387 408
 409 425 454 455 456 457 458 459 460 461 467 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 4
selected features: [  2   3  17  31  38  39  64  78  85 119 121 123 124 125 127 131 169 224
 225 226 230 231 232 233 276 283 284 327 329 333 336 337 348 363 387 409
 414 423 424 425 454 455 456 457 458 459 460 461]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6083437110834371, precision=0.1111111111111111, recall=0.5454545454545454, f1=0.1846153846153846, roc_auc=0.6083437110834371)

info: 5
selected features: [  2  15  31  35  36  38  39  50  51  60  64  68 118 120 121 123 124 125
 146 161 164 177 230 233 238 243 244 262 263 264 265 267 276 333 337 348
 366 367 368 387 409 425 454 455 457 458 461 467]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5666251556662516, precision=0.08256880733944955, recall=0.8181818181818182, f1=0.15000000000000002, roc_auc=0.5666251556662516)

info: 6
selected features: [  2  23  31  38  39  60  64  78 115 117 119 120 121 123 125 126 131 133
 225 226 230 232 233 243 262 276 286 329 333 335 337 346 348 363 387 409
 423 425 445 446 454 455 457 458 459 461 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 7
selected features: [  2  17  23  31  38  39  60  76  79  85 117 121 123 124 125 127 130 139
 163 165 177 187 226 231 233 243 262 276 328 329 335 337 348 363 367 387
 406 409 424 425 454 455 457 458 459 460 461 473]
hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5904109589041096, precision=0.1111111111111111, recall=0.4, f1=0.1739130434782609, roc_auc=0.5904109589041096)

info: 8
selected features: [ 33  35  38  39  51  60  83 115 117 118 119 120 121 123 125 126 127 144
 164 187 215 225 230 231 243 263 265 267 310 327 328 329 333 337 348 363
 364 387 423 424 425 454 455 457 458 459 461 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5924657534246576, precision=0.09803921568627451, recall=0.5, f1=0.1639344262295082, roc_auc=0.5924657534246576)

info: 9
selected features: [ 17  31  35  36  38  39  50  60  78  82 115 119 120 121 123 124 125 127
 144 187 226 231 232 233 243 276 327 328 329 333 334 337 348 363 387 409
 423 424 425 445 454 455 456 457 458 459 461 473]
hyperparameters: {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0641025641025641, recall=1.0, f1=0.12048192771084336, roc_auc=0.5)

score averages:
average balanced accuracy: 0.5847641497445802
average precision: 0.10548405599039465
average recall: 0.7263636363636363
average f1 score: 0.17539427271782837
average roc auc score: 0.5847641497445802
feature counts: Counter({39: 10, 121: 10, 123: 10, 387: 10, 425: 10, 455: 10, 60: 9, 233: 9, 333: 9, 337: 9, 363: 9, 454: 9, 457: 9, 461: 9, 38: 9, 125: 9, 230: 8, 276: 8, 409: 8, 458: 8, 459: 8, 31: 8, 2: 7, 120: 7, 231: 7, 473: 7, 243: 7, 348: 7, 78: 6, 328: 6, 423: 6, 124: 6, 226: 6, 327: 6, 119: 6, 127: 6, 329: 6, 115: 5, 117: 5, 118: 5, 232: 5, 265: 5, 177: 5, 64: 5, 50: 4, 51: 4, 126: 4, 262: 4, 334: 4, 267: 4, 367: 4, 35: 4, 460: 4, 225: 4, 424: 4, 5: 3, 263: 3, 264: 3, 163: 3, 467: 3, 131: 3, 144: 3, 335: 3, 336: 3, 164: 3, 456: 3, 17: 3, 187: 3, 33: 2, 53: 2, 165: 2, 260: 2, 368: 2, 446: 2, 472: 2, 54: 2, 215: 2, 310: 2, 130: 2, 366: 2, 3: 2, 83: 2, 85: 2, 36: 2, 23: 2, 445: 2, 52: 1, 134: 1, 26: 1, 59: 1, 234: 1, 135: 1, 166: 1, 245: 1, 306: 1, 12: 1, 211: 1, 408: 1, 169: 1, 224: 1, 283: 1, 284: 1, 414: 1, 15: 1, 68: 1, 146: 1, 161: 1, 238: 1, 244: 1, 133: 1, 286: 1, 346: 1, 76: 1, 79: 1, 139: 1, 406: 1, 364: 1, 82: 1})
feature stability score: 0.8379629629629629


training results for model: svc, selector function: f_classif, percentile: 20
info: 0
selected features: [ 10  12  19  20  24  26  29  30  31  36  51  54  58  59  60  62  64  73
  89  93  96 104 107 114 115 116 117 118 120 122 123 126 150 151 154 155
 156 157 169 172 176 178 179 181 182 185 187 189 192 211 215 217 249 250
 253 254 255 268 269 271 275 277 278 279 280 281 282 285 286 288 293 305
 314 320 350 351 354 355 356 357 369 372 376 379 381 385 387 389 403 409
 410 427 435 438 441]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5785714285714285, precision=0.125, recall=0.3, f1=0.17647058823529413, roc_auc=0.5785714285714286)

info: 1
selected features: [ 12  19  20  24  26  38  51  53  54  58  59  60  63  64  70  73  84  89
  92  93  95  96  97 104 107 114 115 116 117 118 119 120 122 123 126 135
 150 151 154 155 156 157 169 172 178 179 181 182 187 192 195 208 215 217
 249 250 253 254 255 256 268 271 278 282 286 293 296 309 320 337 350 351
 354 355 356 357 369 372 376 379 381 387 407 409 410 414 426 431 435 438
 441 453 457 459 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5717687074829932, precision=0.11538461538461539, recall=0.3, f1=0.16666666666666669, roc_auc=0.5717687074829932)

info: 2
selected features: [ 12  19  20  23  24  26  30  31  35  36  38  51  53  54  58  59  60  61
  64  70  73  74  84  89  92  93  96 104 107 114 115 116 117 118 120 122
 123 126 150 151 154 155 156 157 166 169 172 176 182 187 192 208 215 217
 236 249 250 253 254 255 256 265 268 271 275 282 286 293 309 320 343 350
 351 354 355 356 357 366 369 372 376 378 387 397 409 410 414 426 427 429
 431 453 457 459 461]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5911564625850341, precision=0.1111111111111111, recall=0.4, f1=0.1739130434782609, roc_auc=0.591156462585034)

info: 3
selected features: [ 12  19  20  24  26  29  30  31  36  38  51  53  54  58  59  63  64  70
  73  84  89  93  96 104 107 114 115 116 117 118 119 120 122 123 126 135
 150 151 154 155 156 157 169 178 179 181 182 187 192 193 215 217 236 249
 250 253 254 255 268 278 282 286 293 294 309 320 343 350 351 354 355 356
 357 369 376 379 381 387 409 410 414 426 434 435 437 438 440 441 449 451
 453 457 459 461 466]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7506226650062267, precision=0.1951219512195122, recall=0.7272727272727273, f1=0.3076923076923077, roc_auc=0.7506226650062267)

info: 4
selected features: [ 12  19  20  24  26  28  29  30  31  51  53  54  58  59  60  63  64  73
  84  89  92  93  95  96 104 114 115 116 117 118 119 120 122 123 126 135
 144 150 151 154 155 156 161 169 172 178 179 181 182 187 192 193 215 236
 243 249 250 253 254 255 268 271 278 282 293 294 309 338 343 350 351 354
 355 356 361 365 369 372 376 378 379 381 387 397 409 426 427 434 435 437
 438 440 441 466 471]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5404732254047322, precision=0.0967741935483871, recall=0.2727272727272727, f1=0.14285714285714285, roc_auc=0.5404732254047322)

info: 5
selected features: [ 12  19  20  24  26  29  30  31  51  53  54  58  59  60  63  70  73  84
  89  92  93  96 104 107 114 115 116 117 118 119 120 122 123 126 131 137
 138 150 151 154 155 156 157 169 172 178 179 182 187 192 215 217 236 237
 249 250 253 254 255 256 268 278 286 293 309 320 333 350 351 353 354 355
 356 357 369 372 378 379 381 387 393 409 410 414 426 427 429 434 435 437
 438 440 441 453 466]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5301992528019925, precision=0.08823529411764706, recall=0.2727272727272727, f1=0.13333333333333333, roc_auc=0.5301992528019925)

info: 6
selected features: [ 12  19  20  23  24  26  30  31  36  38  51  53  54  58  59  60  70  72
  73  84  89  93  95  96 104 107 110 114 115 116 117 118 119 120 122 123
 126 131 150 151 154 155 156 157 169 172 178 179 181 182 187 192 193 215
 217 249 250 253 254 255 256 268 271 278 282 293 309 320 333 350 351 354
 355 356 357 369 372 376 378 379 381 387 397 409 410 414 427 429 435 438
 441 446 457 459 466]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6039850560398505, precision=0.12195121951219512, recall=0.45454545454545453, f1=0.19230769230769232, roc_auc=0.6039850560398506)

info: 7
selected features: [ 12  19  20  23  24  26  29  31  36  38  51  53  54  59  73  75  84  89
  93  96 104 107 108 114 115 116 117 118 120 122 123 126 128 131 136 143
 150 151 154 155 156 157 169 172 176 192 193 215 217 227 235 236 242 249
 250 253 254 255 256 268 293 294 309 320 330 333 338 345 350 351 354 355
 356 357 369 372 376 378 393 397 409 410 414 416 426 434 435 437 438 441
 446 457 459 461 466]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6958904109589041, precision=0.1346153846153846, recall=0.7, f1=0.22580645161290322, roc_auc=0.6958904109589041)

info: 8
selected features: [ 12  19  20  23  24  26  31  36  51  53  54  58  59  60  63  64  73  89
  93  95  96 104 107 114 115 116 117 118 120 122 123 126 131 150 151 154
 155 156 157 169 172 178 179 181 182 185 192 215 217 236 249 250 253 254
 255 256 268 271 282 284 293 305 320 333 343 350 351 354 355 356 357 369
 372 376 378 379 381 385 387 389 403 409 410 414 426 434 435 437 438 440
 441 453 457 459 461]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.654109589041096, precision=0.15151515151515152, recall=0.5, f1=0.23255813953488375, roc_auc=0.6541095890410958)

info: 9
selected features: [ 12  19  20  24  26  31  36  51  53  54  58  59  63  64  70  73  83  84
  92  93  96 104 107 108 114 115 116 117 118 119 120 122 123 126 131 138
 150 151 154 155 156 166 169 170 172 176 178 179 181 182 187 192 215 217
 237 249 250 253 254 255 265 268 269 271 275 282 286 293 309 320 333 343
 350 351 353 354 355 356 366 369 370 372 376 378 379 381 387 393 409 410
 414 427 435 438 441]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6075342465753425, precision=0.12903225806451613, recall=0.4, f1=0.1951219512195122, roc_auc=0.6075342465753425)

score averages:
average balanced accuracy: 0.6124311044467601
average precision: 0.12687411790885203
average recall: 0.43272727272727274
average f1 score: 0.1946727316937997
average roc auc score: 0.6124311044467601
feature counts: Counter({12: 10, 19: 10, 20: 10, 24: 10, 26: 10, 51: 10, 54: 10, 59: 10, 73: 10, 93: 10, 96: 10, 104: 10, 114: 10, 115: 10, 116: 10, 117: 10, 118: 10, 120: 10, 122: 10, 123: 10, 126: 10, 150: 10, 151: 10, 154: 10, 155: 10, 156: 10, 169: 10, 192: 10, 215: 10, 249: 10, 250: 10, 253: 10, 254: 10, 255: 10, 268: 10, 293: 10, 350: 10, 351: 10, 354: 10, 355: 10, 356: 10, 369: 10, 409: 10, 31: 9, 58: 9, 89: 9, 107: 9, 172: 9, 182: 9, 217: 9, 320: 9, 372: 9, 376: 9, 387: 9, 410: 9, 435: 9, 438: 9, 441: 9, 53: 9, 157: 8, 178: 8, 179: 8, 187: 8, 282: 8, 357: 8, 379: 8, 381: 8, 84: 8, 309: 8, 414: 8, 36: 7, 60: 7, 64: 7, 181: 7, 271: 7, 426: 7, 378: 7, 30: 6, 278: 6, 286: 6, 427: 6, 63: 6, 70: 6, 119: 6, 256: 6, 457: 6, 459: 6, 236: 6, 29: 5, 38: 5, 92: 5, 453: 5, 461: 5, 343: 5, 434: 5, 437: 5, 466: 5, 131: 5, 333: 5, 176: 4, 95: 4, 23: 4, 397: 4, 193: 4, 440: 4, 275: 3, 135: 3, 429: 3, 294: 3, 393: 3, 185: 2, 269: 2, 305: 2, 385: 2, 389: 2, 403: 2, 208: 2, 431: 2, 166: 2, 265: 2, 366: 2, 338: 2, 138: 2, 237: 2, 353: 2, 446: 2, 108: 2, 10: 1, 62: 1, 189: 1, 211: 1, 277: 1, 279: 1, 280: 1, 281: 1, 285: 1, 288: 1, 314: 1, 97: 1, 195: 1, 296: 1, 337: 1, 407: 1, 35: 1, 61: 1, 74: 1, 449: 1, 451: 1, 28: 1, 144: 1, 161: 1, 243: 1, 361: 1, 365: 1, 471: 1, 137: 1, 72: 1, 110: 1, 75: 1, 128: 1, 136: 1, 143: 1, 227: 1, 235: 1, 242: 1, 330: 1, 345: 1, 416: 1, 284: 1, 83: 1, 170: 1, 370: 1})
feature stability score: 0.9099415204678363


/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
training results for model: svc, selector function: mutual_info_classif, percentile: 20
info: 0
selected features: [  2   3   5  23  31  33  38  39  50  51  52  54  56  60  67  72  78  83
  85  96 105 114 115 117 118 119 120 121 123 124 125 126 127 130 131 135
 156 157 163 171 173 177 187 192 194 211 214 215 224 226 231 232 233 243
 260 264 265 272 274 276 283 284 327 328 329 333 334 335 337 344 348 363
 367 371 377 387 408 409 414 416 423 424 425 445 454 455 456 457 458 459
 460 461 467 471 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.7309523809523809, precision=0.16666666666666666, recall=0.7, f1=0.2692307692307692, roc_auc=0.7309523809523809)

info: 1
selected features: [  5  17  30  31  32  33  34  35  36  37  38  39  60  64  78  85 103 104
 105 115 120 121 123 124 125 126 127 130 131 132 144 146 163 164 165 168
 177 194 207 215 225 226 230 231 232 233 243 245 260 262 263 265 272 276
 283 284 302 306 327 328 333 335 336 337 344 348 357 361 363 364 367 368
 377 385 387 398 399 404 409 413 414 424 425 427 435 454 455 457 458 459
 461 466 467 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 2
selected features: [  2   5   8  26  30  31  33  35  36  37  38  39  50  51  54  60  67  78
  81  83  85  96 106 114 115 117 118 119 120 121 123 125 127 130 131 132
 133 134 161 165 192 194 215 225 226 230 231 232 233 243 244 260 262 263
 264 265 266 267 274 276 284 292 327 328 329 333 334 335 336 337 348 361
 363 366 367 368 377 387 403 406 409 423 424 425 444 445 447 454 455 457
 458 459 461 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 3
selected features: [  2   3  15  17  26  31  32  35  36  37  38  39  51  53  54  59  60  64
  72  78  82  83  85  96 105 106 114 115 117 119 120 121 122 123 125 126
 127 131 146 157 161 164 168 173 187 194 203 225 230 231 233 243 260 262
 263 264 274 283 284 313 328 329 333 334 337 348 353 363 364 367 368 377
 387 409 410 421 423 424 425 428 445 446 447 454 455 456 457 458 459 460
 461 467 469 472 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.8234744707347448, precision=0.2647058823529412, recall=0.8181818181818182, f1=0.39999999999999997, roc_auc=0.8234744707347448)

info: 4
selected features: [  5  17  23  31  32  34  35  36  38  39  50  51  59  60  64  72  78  81
  82  83  85  86  96 105 114 118 120 121 122 123 125 126 127 161 163 166
 168 173 177 187 192 207 211 226 233 242 243 244 245 247 260 262 263 264
 265 267 274 276 284 314 327 328 329 333 335 337 345 348 361 363 364 366
 367 368 387 408 409 414 421 423 424 425 429 447 454 455 456 457 458 459
 460 461 467 470 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.575653798256538, precision=0.11428571428571428, recall=0.36363636363636365, f1=0.17391304347826086, roc_auc=0.5756537982565381)

info: 5
selected features: [  2   3   5  12  17  19  23  31  36  38  39  53  54  60  64  72  78  82
  83  85  96 105 115 117 118 119 120 121 122 123 124 125 126 127 130 131
 132 133 144 162 165 194 215 230 231 232 233 243 245 260 261 262 263 265
 272 274 275 276 288 293 306 327 328 329 333 334 335 336 337 348 363 366
 367 368 387 406 409 414 423 424 425 445 447 454 455 456 457 458 459 460
 461 467 470 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6323163138231631, precision=0.1276595744680851, recall=0.5454545454545454, f1=0.2068965517241379, roc_auc=0.6323163138231631)

info: 6
selected features: [  2   3   5  17  23  25  31  33  38  39  51  53  56  60  64  78  82  83
  85  96 105 115 117 118 119 120 121 123 124 125 126 127 130 131 134 144
 146 164 171 173 177 215 225 226 230 231 232 233 234 242 243 244 263 264
 267 276 284 286 327 328 329 333 334 335 337 345 346 348 363 368 371 387
 398 399 409 412 414 416 423 424 425 444 445 446 454 455 456 457 458 459
 460 461 467 472 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.49937733499377335, precision=0.06976744186046512, recall=0.2727272727272727, f1=0.11111111111111109, roc_auc=0.49937733499377335)

info: 7
selected features: [  2   3   5  17  25  30  31  33  35  36  37  38  39  52  53  54  60  64
  72  78 115 117 118 119 120 121 123 124 125 127 131 134 146 161 162 163
 164 165 166 168 171 173 187 211 224 230 231 232 233 242 260 262 263 264
 265 267 274 276 283 327 328 329 333 334 335 336 337 348 361 363 364 365
 366 368 387 399 406 408 409 414 423 424 425 444 445 454 455 457 458 459
 460 461 467 472 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.536986301369863, precision=0.08333333333333333, recall=0.3, f1=0.13043478260869565, roc_auc=0.536986301369863)

info: 8
selected features: [  2   5   8  15  17  23  25  26  31  33  35  36  37  38  39  51  52  53
  54  60  64  72  78  85 115 117 118 119 120 121 123 124 125 126 127 133
 134 144 163 165 169 177 194 225 226 230 231 232 233 238 243 245 250 262
 263 264 265 267 274 276 283 322 327 328 329 333 334 335 336 337 344 348
 363 364 366 367 368 377 387 409 423 424 425 426 445 446 447 454 455 457
 458 459 461 470 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5767123287671233, precision=0.1, recall=0.4, f1=0.16000000000000003, roc_auc=0.5767123287671233)

info: 9
selected features: [  2  17  25  30  31  34  35  36  38  39  51  52  53  58  60  64  78  83
  85  99 106 114 115 117 118 119 120 121 123 125 127 131 132 134 139 144
 165 177 187 199 207 211 224 225 226 230 231 232 233 262 263 264 265 274
 275 276 283 284 302 310 327 328 329 334 335 336 337 348 363 366 367 368
 377 387 406 409 423 424 425 435 445 446 454 455 456 457 458 459 460 461
 463 467 470 472 473]
hyperparameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5458904109589041, precision=0.08163265306122448, recall=0.4, f1=0.13559322033898302, roc_auc=0.5458904109589041)

score averages:
average balanced accuracy: 0.592136333985649
average precision: 0.10080512660284302
average recall: 0.38
average f1 score: 0.15871794784919577
average roc auc score: 0.592136333985649
feature counts: Counter({31: 10, 38: 10, 39: 10, 60: 10, 78: 10, 120: 10, 121: 10, 123: 10, 125: 10, 127: 10, 233: 10, 328: 10, 337: 10, 348: 10, 363: 10, 387: 10, 409: 10, 424: 10, 425: 10, 454: 10, 455: 10, 457: 10, 458: 10, 459: 10, 461: 10, 473: 10, 85: 9, 115: 9, 231: 9, 276: 9, 327: 9, 329: 9, 333: 9, 335: 9, 423: 9, 263: 9, 368: 9, 2: 8, 5: 8, 117: 8, 118: 8, 119: 8, 131: 8, 232: 8, 243: 8, 264: 8, 265: 8, 274: 8, 334: 8, 367: 8, 445: 8, 467: 8, 17: 8, 36: 8, 64: 8, 230: 8, 262: 8, 51: 7, 83: 7, 126: 7, 226: 7, 260: 7, 284: 7, 460: 7, 35: 7, 472: 7, 33: 6, 54: 6, 72: 6, 96: 6, 105: 6, 124: 6, 177: 6, 194: 6, 283: 6, 377: 6, 414: 6, 456: 6, 165: 6, 225: 6, 336: 6, 366: 6, 53: 6, 3: 5, 23: 5, 114: 5, 130: 5, 163: 5, 173: 5, 187: 5, 215: 5, 37: 5, 144: 5, 364: 5, 134: 5, 267: 5, 447: 5, 52: 4, 211: 4, 30: 4, 132: 4, 146: 4, 164: 4, 168: 4, 245: 4, 361: 4, 161: 4, 406: 4, 82: 4, 446: 4, 470: 4, 25: 4, 50: 3, 171: 3, 192: 3, 224: 3, 272: 3, 344: 3, 408: 3, 32: 3, 34: 3, 207: 3, 399: 3, 26: 3, 106: 3, 133: 3, 244: 3, 444: 3, 122: 3, 242: 3, 56: 2, 67: 2, 157: 2, 371: 2, 416: 2, 302: 2, 306: 2, 398: 2, 435: 2, 8: 2, 81: 2, 15: 2, 59: 2, 421: 2, 166: 2, 345: 2, 162: 2, 275: 2, 135: 1, 156: 1, 214: 1, 471: 1, 103: 1, 104: 1, 357: 1, 385: 1, 404: 1, 413: 1, 427: 1, 466: 1, 266: 1, 292: 1, 403: 1, 203: 1, 313: 1, 353: 1, 410: 1, 428: 1, 469: 1, 86: 1, 247: 1, 314: 1, 429: 1, 12: 1, 19: 1, 261: 1, 288: 1, 293: 1, 234: 1, 286: 1, 346: 1, 412: 1, 365: 1, 169: 1, 238: 1, 250: 1, 322: 1, 426: 1, 58: 1, 99: 1, 139: 1, 199: 1, 310: 1, 463: 1})
feature stability score: 0.8842105263157894


/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
training results for model: svc, selector function: f_classif, percentile: 100
info: 0
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 1
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 2
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 3
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 4
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 5
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5326899128268991, precision=0.10526315789473684, recall=0.18181818181818182, f1=0.13333333333333333, roc_auc=0.5326899128268991)

info: 6
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 7
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0641025641025641, recall=1.0, f1=0.12048192771084336, roc_auc=0.5)

info: 8
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6746575342465753, precision=0.18518518518518517, recall=0.5, f1=0.2702702702702703, roc_auc=0.6746575342465755)

info: 9
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6472602739726028, precision=0.14285714285714285, recall=0.5, f1=0.22222222222222224, roc_auc=0.6472602739726028)

score averages:
average balanced accuracy: 0.5354607721046077
average precision: 0.07075991328421767
average recall: 0.5181818181818182
average f1 score: 0.11391648963938121
average roc auc score: 0.5354607721046077
feature counts: Counter({0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10, 14: 10, 15: 10, 16: 10, 17: 10, 18: 10, 19: 10, 20: 10, 21: 10, 22: 10, 23: 10, 24: 10, 25: 10, 26: 10, 27: 10, 28: 10, 29: 10, 30: 10, 31: 10, 32: 10, 33: 10, 34: 10, 35: 10, 36: 10, 37: 10, 38: 10, 39: 10, 40: 10, 41: 10, 42: 10, 43: 10, 44: 10, 45: 10, 46: 10, 47: 10, 48: 10, 49: 10, 50: 10, 51: 10, 52: 10, 53: 10, 54: 10, 55: 10, 56: 10, 57: 10, 58: 10, 59: 10, 60: 10, 61: 10, 62: 10, 63: 10, 64: 10, 65: 10, 66: 10, 67: 10, 68: 10, 69: 10, 70: 10, 71: 10, 72: 10, 73: 10, 74: 10, 75: 10, 76: 10, 77: 10, 78: 10, 79: 10, 80: 10, 81: 10, 82: 10, 83: 10, 84: 10, 85: 10, 86: 10, 87: 10, 88: 10, 89: 10, 90: 10, 91: 10, 92: 10, 93: 10, 94: 10, 95: 10, 96: 10, 97: 10, 98: 10, 99: 10, 100: 10, 101: 10, 102: 10, 103: 10, 104: 10, 105: 10, 106: 10, 107: 10, 108: 10, 109: 10, 110: 10, 111: 10, 112: 10, 113: 10, 114: 10, 115: 10, 116: 10, 117: 10, 118: 10, 119: 10, 120: 10, 121: 10, 122: 10, 123: 10, 124: 10, 125: 10, 126: 10, 127: 10, 128: 10, 129: 10, 130: 10, 131: 10, 132: 10, 133: 10, 134: 10, 135: 10, 136: 10, 137: 10, 138: 10, 139: 10, 140: 10, 141: 10, 142: 10, 143: 10, 144: 10, 145: 10, 146: 10, 147: 10, 148: 10, 149: 10, 150: 10, 151: 10, 152: 10, 153: 10, 154: 10, 155: 10, 156: 10, 157: 10, 158: 10, 159: 10, 160: 10, 161: 10, 162: 10, 163: 10, 164: 10, 165: 10, 166: 10, 167: 10, 168: 10, 169: 10, 170: 10, 171: 10, 172: 10, 173: 10, 174: 10, 175: 10, 176: 10, 177: 10, 178: 10, 179: 10, 180: 10, 181: 10, 182: 10, 183: 10, 184: 10, 185: 10, 186: 10, 187: 10, 188: 10, 189: 10, 190: 10, 191: 10, 192: 10, 193: 10, 194: 10, 195: 10, 196: 10, 197: 10, 198: 10, 199: 10, 200: 10, 201: 10, 202: 10, 203: 10, 204: 10, 205: 10, 206: 10, 207: 10, 208: 10, 209: 10, 210: 10, 211: 10, 212: 10, 213: 10, 214: 10, 215: 10, 216: 10, 217: 10, 218: 10, 219: 10, 220: 10, 221: 10, 222: 10, 223: 10, 224: 10, 225: 10, 226: 10, 227: 10, 228: 10, 229: 10, 230: 10, 231: 10, 232: 10, 233: 10, 234: 10, 235: 10, 236: 10, 237: 10, 238: 10, 239: 10, 240: 10, 241: 10, 242: 10, 243: 10, 244: 10, 245: 10, 246: 10, 247: 10, 248: 10, 249: 10, 250: 10, 251: 10, 252: 10, 253: 10, 254: 10, 255: 10, 256: 10, 257: 10, 258: 10, 259: 10, 260: 10, 261: 10, 262: 10, 263: 10, 264: 10, 265: 10, 266: 10, 267: 10, 268: 10, 269: 10, 270: 10, 271: 10, 272: 10, 273: 10, 274: 10, 275: 10, 276: 10, 277: 10, 278: 10, 279: 10, 280: 10, 281: 10, 282: 10, 283: 10, 284: 10, 285: 10, 286: 10, 287: 10, 288: 10, 289: 10, 290: 10, 291: 10, 292: 10, 293: 10, 294: 10, 295: 10, 296: 10, 297: 10, 298: 10, 299: 10, 300: 10, 301: 10, 302: 10, 303: 10, 304: 10, 305: 10, 306: 10, 307: 10, 308: 10, 309: 10, 310: 10, 311: 10, 312: 10, 313: 10, 314: 10, 315: 10, 316: 10, 317: 10, 318: 10, 319: 10, 320: 10, 321: 10, 322: 10, 323: 10, 324: 10, 325: 10, 326: 10, 327: 10, 328: 10, 329: 10, 330: 10, 331: 10, 332: 10, 333: 10, 334: 10, 335: 10, 336: 10, 337: 10, 338: 10, 339: 10, 340: 10, 341: 10, 342: 10, 343: 10, 344: 10, 345: 10, 346: 10, 347: 10, 348: 10, 349: 10, 350: 10, 351: 10, 352: 10, 353: 10, 354: 10, 355: 10, 356: 10, 357: 10, 358: 10, 359: 10, 360: 10, 361: 10, 362: 10, 363: 10, 364: 10, 365: 10, 366: 10, 367: 10, 368: 10, 369: 10, 370: 10, 371: 10, 372: 10, 373: 10, 374: 10, 375: 10, 376: 10, 377: 10, 378: 10, 379: 10, 380: 10, 381: 10, 382: 10, 383: 10, 384: 10, 385: 10, 386: 10, 387: 10, 388: 10, 389: 10, 390: 10, 391: 10, 392: 10, 393: 10, 394: 10, 395: 10, 396: 10, 397: 10, 398: 10, 399: 10, 400: 10, 401: 10, 402: 10, 403: 10, 404: 10, 405: 10, 406: 10, 407: 10, 408: 10, 409: 10, 410: 10, 411: 10, 412: 10, 413: 10, 414: 10, 415: 10, 416: 10, 417: 10, 418: 10, 419: 10, 420: 10, 421: 10, 422: 10, 423: 10, 424: 10, 425: 10, 426: 10, 427: 10, 428: 10, 429: 10, 430: 10, 431: 10, 432: 10, 433: 10, 434: 10, 435: 10, 436: 10, 437: 10, 438: 10, 439: 10, 440: 10, 441: 10, 442: 10, 443: 10, 444: 10, 445: 10, 446: 10, 447: 10, 448: 10, 449: 10, 450: 10, 451: 10, 452: 10, 453: 10, 454: 10, 455: 10, 456: 10, 457: 10, 458: 10, 459: 10, 460: 10, 461: 10, 462: 10, 463: 10, 464: 10, 465: 10, 466: 10, 467: 10, 468: 10, 469: 10, 470: 10, 471: 10, 472: 10, 473: 10})
feature stability score: 1.0


/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/natejh/spring-2020/machine-learning/final-project/venv/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
training results for model: svc, selector function: mutual_info_classif, percentile: 100
info: 0
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 1
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 2
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0, recall=0.0, f1=0.0, roc_auc=0.5)

info: 3
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 4
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 5
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 6
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.07006369426751592, recall=1.0, f1=0.13095238095238096, roc_auc=0.5)

info: 7
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5643835616438356, precision=0.10714285714285714, recall=0.3, f1=0.15789473684210525, roc_auc=0.5643835616438356)

info: 8
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.5, precision=0.0641025641025641, recall=1.0, f1=0.12048192771084336, roc_auc=0.5)

info: 9
selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473]
hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000000}
scores: Scores(balanced_accuracy=0.6246575342465753, precision=0.15384615384615385, recall=0.4, f1=0.2222222222222222, roc_auc=0.6246575342465753)

score averages:
average balanced accuracy: 0.5189041095890411
average precision: 0.060534635216163875
average recall: 0.57
average f1 score: 0.10244084105846947
average roc auc score: 0.5189041095890411
feature counts: Counter({0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10, 14: 10, 15: 10, 16: 10, 17: 10, 18: 10, 19: 10, 20: 10, 21: 10, 22: 10, 23: 10, 24: 10, 25: 10, 26: 10, 27: 10, 28: 10, 29: 10, 30: 10, 31: 10, 32: 10, 33: 10, 34: 10, 35: 10, 36: 10, 37: 10, 38: 10, 39: 10, 40: 10, 41: 10, 42: 10, 43: 10, 44: 10, 45: 10, 46: 10, 47: 10, 48: 10, 49: 10, 50: 10, 51: 10, 52: 10, 53: 10, 54: 10, 55: 10, 56: 10, 57: 10, 58: 10, 59: 10, 60: 10, 61: 10, 62: 10, 63: 10, 64: 10, 65: 10, 66: 10, 67: 10, 68: 10, 69: 10, 70: 10, 71: 10, 72: 10, 73: 10, 74: 10, 75: 10, 76: 10, 77: 10, 78: 10, 79: 10, 80: 10, 81: 10, 82: 10, 83: 10, 84: 10, 85: 10, 86: 10, 87: 10, 88: 10, 89: 10, 90: 10, 91: 10, 92: 10, 93: 10, 94: 10, 95: 10, 96: 10, 97: 10, 98: 10, 99: 10, 100: 10, 101: 10, 102: 10, 103: 10, 104: 10, 105: 10, 106: 10, 107: 10, 108: 10, 109: 10, 110: 10, 111: 10, 112: 10, 113: 10, 114: 10, 115: 10, 116: 10, 117: 10, 118: 10, 119: 10, 120: 10, 121: 10, 122: 10, 123: 10, 124: 10, 125: 10, 126: 10, 127: 10, 128: 10, 129: 10, 130: 10, 131: 10, 132: 10, 133: 10, 134: 10, 135: 10, 136: 10, 137: 10, 138: 10, 139: 10, 140: 10, 141: 10, 142: 10, 143: 10, 144: 10, 145: 10, 146: 10, 147: 10, 148: 10, 149: 10, 150: 10, 151: 10, 152: 10, 153: 10, 154: 10, 155: 10, 156: 10, 157: 10, 158: 10, 159: 10, 160: 10, 161: 10, 162: 10, 163: 10, 164: 10, 165: 10, 166: 10, 167: 10, 168: 10, 169: 10, 170: 10, 171: 10, 172: 10, 173: 10, 174: 10, 175: 10, 176: 10, 177: 10, 178: 10, 179: 10, 180: 10, 181: 10, 182: 10, 183: 10, 184: 10, 185: 10, 186: 10, 187: 10, 188: 10, 189: 10, 190: 10, 191: 10, 192: 10, 193: 10, 194: 10, 195: 10, 196: 10, 197: 10, 198: 10, 199: 10, 200: 10, 201: 10, 202: 10, 203: 10, 204: 10, 205: 10, 206: 10, 207: 10, 208: 10, 209: 10, 210: 10, 211: 10, 212: 10, 213: 10, 214: 10, 215: 10, 216: 10, 217: 10, 218: 10, 219: 10, 220: 10, 221: 10, 222: 10, 223: 10, 224: 10, 225: 10, 226: 10, 227: 10, 228: 10, 229: 10, 230: 10, 231: 10, 232: 10, 233: 10, 234: 10, 235: 10, 236: 10, 237: 10, 238: 10, 239: 10, 240: 10, 241: 10, 242: 10, 243: 10, 244: 10, 245: 10, 246: 10, 247: 10, 248: 10, 249: 10, 250: 10, 251: 10, 252: 10, 253: 10, 254: 10, 255: 10, 256: 10, 257: 10, 258: 10, 259: 10, 260: 10, 261: 10, 262: 10, 263: 10, 264: 10, 265: 10, 266: 10, 267: 10, 268: 10, 269: 10, 270: 10, 271: 10, 272: 10, 273: 10, 274: 10, 275: 10, 276: 10, 277: 10, 278: 10, 279: 10, 280: 10, 281: 10, 282: 10, 283: 10, 284: 10, 285: 10, 286: 10, 287: 10, 288: 10, 289: 10, 290: 10, 291: 10, 292: 10, 293: 10, 294: 10, 295: 10, 296: 10, 297: 10, 298: 10, 299: 10, 300: 10, 301: 10, 302: 10, 303: 10, 304: 10, 305: 10, 306: 10, 307: 10, 308: 10, 309: 10, 310: 10, 311: 10, 312: 10, 313: 10, 314: 10, 315: 10, 316: 10, 317: 10, 318: 10, 319: 10, 320: 10, 321: 10, 322: 10, 323: 10, 324: 10, 325: 10, 326: 10, 327: 10, 328: 10, 329: 10, 330: 10, 331: 10, 332: 10, 333: 10, 334: 10, 335: 10, 336: 10, 337: 10, 338: 10, 339: 10, 340: 10, 341: 10, 342: 10, 343: 10, 344: 10, 345: 10, 346: 10, 347: 10, 348: 10, 349: 10, 350: 10, 351: 10, 352: 10, 353: 10, 354: 10, 355: 10, 356: 10, 357: 10, 358: 10, 359: 10, 360: 10, 361: 10, 362: 10, 363: 10, 364: 10, 365: 10, 366: 10, 367: 10, 368: 10, 369: 10, 370: 10, 371: 10, 372: 10, 373: 10, 374: 10, 375: 10, 376: 10, 377: 10, 378: 10, 379: 10, 380: 10, 381: 10, 382: 10, 383: 10, 384: 10, 385: 10, 386: 10, 387: 10, 388: 10, 389: 10, 390: 10, 391: 10, 392: 10, 393: 10, 394: 10, 395: 10, 396: 10, 397: 10, 398: 10, 399: 10, 400: 10, 401: 10, 402: 10, 403: 10, 404: 10, 405: 10, 406: 10, 407: 10, 408: 10, 409: 10, 410: 10, 411: 10, 412: 10, 413: 10, 414: 10, 415: 10, 416: 10, 417: 10, 418: 10, 419: 10, 420: 10, 421: 10, 422: 10, 423: 10, 424: 10, 425: 10, 426: 10, 427: 10, 428: 10, 429: 10, 430: 10, 431: 10, 432: 10, 433: 10, 434: 10, 435: 10, 436: 10, 437: 10, 438: 10, 439: 10, 440: 10, 441: 10, 442: 10, 443: 10, 444: 10, 445: 10, 446: 10, 447: 10, 448: 10, 449: 10, 450: 10, 451: 10, 452: 10, 453: 10, 454: 10, 455: 10, 456: 10, 457: 10, 458: 10, 459: 10, 460: 10, 461: 10, 462: 10, 463: 10, 464: 10, 465: 10, 466: 10, 467: 10, 468: 10, 469: 10, 470: 10, 471: 10, 472: 10, 473: 10})
feature stability score: 1.0


